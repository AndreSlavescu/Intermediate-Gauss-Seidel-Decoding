{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMsI6oWpdhR9CWCj6HCFlog",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreSlavescu/Intermediate-Gauss-Seidel-Decoding/blob/main/Intermediate_Gauss_Seidel_Decoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SJxEa2i2DbYt",
        "outputId": "d46ab5dc-9bcf-4eba-9f73-0d043f79f125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 24 00:36:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "id": "rcGEzU1C2sQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "import random\n",
        "\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n",
        "from pycuda.driver import Event\n",
        "\n",
        "# typing\n",
        "from typing import List, Tuple\n",
        "\n",
        "# Kernel code\n",
        "\"\"\"\n",
        "Idea:\n",
        "\n",
        "The Gauss-Seidel Iteration Method, while inherently parallel for computing indices\n",
        "of the vector x in Ax = b, it suffers from a sequential nature when computing n > 1\n",
        "iterations. The idea with the below kernel is to perform a sort of \"jump iteration\",\n",
        "where even indices of x are computed for even iterations and odd indices for odd iterations,\n",
        "allowing for a two-fold parallelism in the convergence for finding the solution.\n",
        "The implementation below along with the test for 100 iterations suggests that this ideology\n",
        "may be effective, and can be applied to problems such as parallel token decoding in LLMs,\n",
        "as seen in lookahead decoding (https://lmsys.org/blog/2023-11-21-lookahead-decoding/).\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "kernel_code = '''\n",
        "__global__ void jump_iteration_gauss_seidel(float *A, float *b, float *x_1, float *x_2, int size, int iterations) {\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (index >= size) return;\n",
        "\n",
        "    float *x_read, *x_write;\n",
        "\n",
        "    if (index < size) {\n",
        "        // initialize both buffers\n",
        "        x_1[index] = 0.0;\n",
        "        x_2[index] = 0.0;\n",
        "        __syncthreads();\n",
        "\n",
        "        #pragma unroll\n",
        "        for (int iter = 0; iter < iterations; ++iter) {\n",
        "            // Determine the read and write buffers\n",
        "            if (iter % 2 == 0) {\n",
        "                x_read = x_1;\n",
        "                x_write = x_2;\n",
        "            } else {\n",
        "                x_read = x_2;\n",
        "                x_write = x_1;\n",
        "            }\n",
        "\n",
        "            // jump iteration update logic\n",
        "            bool even_iteration = (iter % 2 == 0);\n",
        "            bool is_even_index = ((index / sqrt((float)size)) + ((index % (int)sqrt((float)size))) % 2 == 0);\n",
        "\n",
        "            if (even_iteration == is_even_index) {\n",
        "                float sum = 0.0;\n",
        "\n",
        "                #pragma unroll\n",
        "                for (int j = 0; j < size; ++j) {\n",
        "                    if (j != index) {\n",
        "                        sum += A[index * size + j] * x_read[j];\n",
        "                    }\n",
        "                }\n",
        "                x_write[index] = (b[index] - sum) / A[index * size + index];\n",
        "            } else {\n",
        "                x_write[index] = x_read[index];\n",
        "            }\n",
        "            __syncthreads();\n",
        "        }\n",
        "\n",
        "        // assign latest values to x_1\n",
        "        if (iterations % 2 != 0) {\n",
        "            x_1[index] = x_2[index];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "\n",
        "# Compile the kernel code\n",
        "mod = SourceModule(kernel_code)\n",
        "jump_iteration_gauss_seidel = mod.get_function(\"jump_iteration_gauss_seidel\")\n",
        "\n",
        "def run_gauss_seidel_gpu(\n",
        "    A: np.array,\n",
        "    b: np.array,\n",
        "    x: np.array,\n",
        "    size: int,\n",
        "    iterations: int\n",
        "  ) -> bytes:\n",
        "    A_gpu = cuda.mem_alloc(A.nbytes)\n",
        "    b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "    x_gpu_1 = cuda.mem_alloc(x.nbytes)\n",
        "    x_gpu_2 = cuda.mem_alloc(x.nbytes)\n",
        "\n",
        "    # host to device copy\n",
        "    cuda.memcpy_htod(A_gpu, A)\n",
        "    cuda.memcpy_htod(b_gpu, b)\n",
        "    cuda.memcpy_htod(x_gpu_1, x)\n",
        "\n",
        "    block_size = 256\n",
        "    grid_size = int(np.ceil(size / block_size))\n",
        "\n",
        "    # Time kernel for 100 iterations\n",
        "    start = cuda.Event()\n",
        "    end = cuda.Event()\n",
        "    start.record()\n",
        "\n",
        "    jump_iteration_gauss_seidel(A_gpu, b_gpu, x_gpu_1, x_gpu_2, np.int32(size), np.int32(iterations),\n",
        "                              block=(block_size, 1, 1), grid=(grid_size, 1))\n",
        "\n",
        "    end.record()\n",
        "    end.synchronize()\n",
        "\n",
        "    # Calculate the elapsed time\n",
        "    elapsed_time = start.time_till(end)\n",
        "    print(f\"Kernel execution time: {elapsed_time} milliseconds\")\n",
        "\n",
        "    # device to host copy\n",
        "    cuda.memcpy_dtoh(x, x_gpu_1)\n",
        "    return x\n",
        "\n",
        "def generate_test_equation(size: int) -> Tuple[np.array, np.array]:\n",
        "    \"\"\"Random testcase for Ax = b\"\"\"\n",
        "    # diagonally dominant matrix for convergence\n",
        "    A = np.random.rand(size, size).astype(np.float32)\n",
        "    for i in range(size):\n",
        "        A[i, i] += size\n",
        "    b = np.random.rand(size).astype(np.float32)\n",
        "    return A, b\n",
        "\n",
        "def test_gauss_seidel_gpu(\n",
        "    test_cases: int = 20,\n",
        "    size_range: Tuple[int, int] = (3, 100),\n",
        "    iterations: int = 100\n",
        "  ) -> bool:\n",
        "    \"\"\"Test the Intermediate Gauss-Seidel Decoding implementation with multiple random test cases.\"\"\"\n",
        "    for _ in range(test_cases):\n",
        "        size = random.randint(*size_range)\n",
        "        A, b = generate_test_equation(size)\n",
        "        x0 = np.zeros_like(b)\n",
        "\n",
        "        x_gpu = run_gauss_seidel_gpu(A, b, x0.copy(), len(b), iterations)\n",
        "        x_real = la.solve(A, b)\n",
        "\n",
        "        # Compare the results\n",
        "        if not np.allclose(x_gpu, x_real, atol=1e-3):\n",
        "            print(f\"Test Failed for size {size}\")\n",
        "            print(\"GPU Result:\", x_gpu)\n",
        "            print(\"True Result:\", x_real)\n",
        "            print(f\"Difference: {np.linalg.norm(x_gpu - x_real)}\\n\")\n",
        "            return False\n",
        "        else:\n",
        "            print(f\"Test Passed for size: {size}\\n\")\n",
        "\n",
        "    print(\"\\n\\n#################\\n\\nAll tests passed! \\n\\n#################\")\n",
        "    return True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # Run the test harness\n",
        "  test_gauss_seidel_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64AQizF0DxrY",
        "outputId": "fa73d8f6-36ec-4cf6-b5cd-22f98d7d8170"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel execution time: 0.2595199942588806 milliseconds\n",
            "Test Passed for size: 27\n",
            "\n",
            "Kernel execution time: 0.6021119952201843 milliseconds\n",
            "Test Passed for size: 78\n",
            "\n",
            "Kernel execution time: 0.3318080008029938 milliseconds\n",
            "Test Passed for size: 47\n",
            "\n",
            "Kernel execution time: 0.30163198709487915 milliseconds\n",
            "Test Passed for size: 41\n",
            "\n",
            "Kernel execution time: 0.753600001335144 milliseconds\n",
            "Test Passed for size: 92\n",
            "\n",
            "Kernel execution time: 0.15772800147533417 milliseconds\n",
            "Test Passed for size: 16\n",
            "\n",
            "Kernel execution time: 0.30559998750686646 milliseconds\n",
            "Test Passed for size: 44\n",
            "\n",
            "Kernel execution time: 0.16291199624538422 milliseconds\n",
            "Test Passed for size: 15\n",
            "\n",
            "Kernel execution time: 0.3742719888687134 milliseconds\n",
            "Test Passed for size: 56\n",
            "\n",
            "Kernel execution time: 0.8007680177688599 milliseconds\n",
            "Test Passed for size: 97\n",
            "\n",
            "Kernel execution time: 0.2457599937915802 milliseconds\n",
            "Test Passed for size: 31\n",
            "\n",
            "Kernel execution time: 0.3624959886074066 milliseconds\n",
            "Test Passed for size: 53\n",
            "\n",
            "Kernel execution time: 0.21615999937057495 milliseconds\n",
            "Test Passed for size: 26\n",
            "\n",
            "Kernel execution time: 0.3072640001773834 milliseconds\n",
            "Test Passed for size: 42\n",
            "\n",
            "Kernel execution time: 0.655135989189148 milliseconds\n",
            "Test Passed for size: 89\n",
            "\n",
            "Kernel execution time: 0.3587520122528076 milliseconds\n",
            "Test Passed for size: 53\n",
            "\n",
            "Kernel execution time: 0.17151999473571777 milliseconds\n",
            "Test Passed for size: 20\n",
            "\n",
            "Kernel execution time: 0.5206400156021118 milliseconds\n",
            "Test Passed for size: 75\n",
            "\n",
            "Kernel execution time: 0.2714560031890869 milliseconds\n",
            "Test Passed for size: 35\n",
            "\n",
            "Kernel execution time: 0.3139199912548065 milliseconds\n",
            "Test Passed for size: 43\n",
            "\n",
            "\n",
            "\n",
            "#################\n",
            "\n",
            "All tests passed! \n",
            "\n",
            "#################\n"
          ]
        }
      ]
    }
  ]
}