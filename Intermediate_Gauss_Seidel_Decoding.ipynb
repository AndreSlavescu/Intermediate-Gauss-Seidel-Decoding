{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmy5Q5Ca8oFs1K32LhK5dV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreSlavescu/Intermediate-Gauss-Seidel-Decoding/blob/main/Intermediate_Gauss_Seidel_Decoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJxEa2i2DbYt"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "id": "rcGEzU1C2sQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n",
        "from pycuda.driver import Event\n",
        "\n",
        "# Kernel code\n",
        "\"\"\"\n",
        "Idea:\n",
        "\n",
        "The Gauss-Seidel Iteration Method, while inherently parallel for computing indices\n",
        "of the vector x in Ax = b, it suffers from a sequential nature when computing n > 1\n",
        "iterations. The idea with the below kernel is to perform a sort of \"jump iteration\",\n",
        "where even indices of x are computed for even iterations and odd indices for odd iterations,\n",
        "allowing for a two-fold parallelism in the convergence for finding the solution.\n",
        "The implementation below along with the test for 100 iterations suggests that this ideology\n",
        "may be effective, and can be applied to problems such as parallel token decoding in LLMs,\n",
        "as seen in lookahead decoding (https://lmsys.org/blog/2023-11-21-lookahead-decoding/).\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "kernel_code = '''\n",
        "__global__ void jump_iteration_gauss_seidel(float *A, float *b, float *x_1, float *x_2, int size, int iterations) {\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float *x_read, *x_write;\n",
        "\n",
        "    if (index < size) {\n",
        "        #pragma unroll\n",
        "        for (int iter = 0; iter < iterations; ++iter) {\n",
        "            // Determine the read and write buffers\n",
        "            if (iter % 2 == 0) {\n",
        "                x_read = x_1;\n",
        "                x_write = x_2;\n",
        "            } else {\n",
        "                x_read = x_2;\n",
        "                x_write = x_1;\n",
        "            }\n",
        "\n",
        "            // jump iteration update logic\n",
        "            bool even_iteration = (iter % 2 == 0);\n",
        "            bool is_even_index = ((index / sqrt((float)size)) + ((index % (int)sqrt((float)size))) % 2 == 0);\n",
        "\n",
        "            if (even_iteration == is_even_index) {\n",
        "                float sum = 0.0;\n",
        "\n",
        "                #pragma unroll\n",
        "                for (int j = 0; j < size; ++j) {\n",
        "                    if (j != index) {\n",
        "                        sum += A[index * size + j] * x_read[j];\n",
        "                    }\n",
        "                }\n",
        "                x_write[index] = (b[index] - sum) / A[index * size + index];\n",
        "            } else {\n",
        "                x_write[index] = x_read[index];\n",
        "            }\n",
        "            __syncthreads();\n",
        "        }\n",
        "\n",
        "        // assign latest values to x_1\n",
        "        if (iterations % 2 != 0 && index < size) {\n",
        "            x_1[index] = x_write[index];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "'''\n",
        "\n",
        "# Compile the kernel code\n",
        "mod = SourceModule(kernel_code)\n",
        "jump_iteration_gauss_seidel = mod.get_function(\"jump_iteration_gauss_seidel\")\n",
        "\n",
        "def run_gauss_seidel_gpu(A, b, x, size, iterations):\n",
        "    A_gpu = cuda.mem_alloc(A.nbytes)\n",
        "    b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "    x_gpu_1 = cuda.mem_alloc(x.nbytes)\n",
        "    x_gpu_2 = cuda.mem_alloc(x.nbytes)\n",
        "\n",
        "    # host to device copy\n",
        "    cuda.memcpy_htod(A_gpu, A)\n",
        "    cuda.memcpy_htod(b_gpu, b)\n",
        "    cuda.memcpy_htod(x_gpu_1, x)\n",
        "\n",
        "    block_size = 256\n",
        "    grid_size = int(np.ceil(size / block_size))\n",
        "\n",
        "    # Time kernel for 100 iterations\n",
        "    start = cuda.Event()\n",
        "    end = cuda.Event()\n",
        "    start.record()\n",
        "\n",
        "    jump_iteration_gauss_seidel(A_gpu, b_gpu, x_gpu_1, x_gpu_2, np.int32(size), np.int32(iterations),\n",
        "                              block=(block_size, 1, 1), grid=(grid_size, 1))\n",
        "\n",
        "    end.record()\n",
        "    end.synchronize()\n",
        "\n",
        "    # Calculate the elapsed time\n",
        "    elapsed_time = start.time_till(end)\n",
        "    print(f\"Kernel execution time: {elapsed_time} milliseconds\")\n",
        "\n",
        "    # device to host copy\n",
        "    cuda.memcpy_dtoh(x, x_gpu_1)\n",
        "    return x\n",
        "\n",
        "# Test system\n",
        "A = np.array([[10.0, -1.0, 2.0], [-1.0, 11.0, -1.0], [2.0, -1.0, 10.0]], dtype=np.float32)\n",
        "b = np.array([6.0, 25.0, -11.0], dtype=np.float32)\n",
        "x0 = np.zeros_like(b)\n",
        "\n",
        "iterations = 100\n",
        "x_gpu = run_gauss_seidel_gpu(A, b, x0.copy(), len(b), iterations)\n",
        "\n",
        "# solve system\n",
        "x_correct = la.solve(A, b)\n",
        "\n",
        "print()\n",
        "print(\"GPU Result:\", x_gpu)\n",
        "print(\"Correct Solution:\", x_correct)\n",
        "print()\n",
        "\n",
        "assert np.allclose(x_gpu, x_correct), \"GPU result does not match correct solution\"\n",
        "print(\"GPU result matches correct solution\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64AQizF0DxrY",
        "outputId": "ad228a5d-6032-4bd3-b167-715b1980ae78"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel execution time: 0.14905600249767303 milliseconds\n",
            "\n",
            "GPU Result: [ 1.0432693  2.2692308 -1.0817307]\n",
            "Correct Solution: [ 1.0432693  2.2692308 -1.0817307]\n",
            "\n",
            "GPU result matches correct solution\n"
          ]
        }
      ]
    }
  ]
}